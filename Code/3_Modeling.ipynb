{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Notebook\n",
    "## Notebook Goal\n",
    "With all the data prepared and ready to go, it's time to start modelling. This means I'm going to have to vectorize my data in some way, grid search through some models as well as through their parameters, and establish some final predictive model. The modelling parameters are going to be heavily focused on preventing overfitness so that it can generalize well. That will be the biggest detractor here. My model might be overly specific and really good at predicting documents that are very similar to the one it was trained on but since in the testing data we're dealing with irrationality we're going to have a lot of False positives.\n",
    "\n",
    "## WorkFlow \n",
    "\n",
    "**1)** Create a Baseline model to compare our models to. <br>\n",
    "**2)** Separate space for each of the four training DataSets. <br> \n",
    "**3)** Transform each dataset using either CountVectorizer or Tfidf. <br>\n",
    "**4)** Try the following models on the data: Logistic Regression, Naive Bayes, Random Forest, Extra Trees and AdaBooster. <br>\n",
    "**5)** Choose the best model from each data set and create a combined prediction from all of them. <br>\n",
    "\n",
    "## Table of Contents\n",
    "1) **Establish Baseline Model**\n",
    "- [Baseline Model](#Establish-Baseline-Model)\n",
    "\n",
    "2) **Short Emotion Data**\n",
    "- [Count Vectorized](#Count-Vectorized-Short-Emotion-Data)\n",
    "- [Tfidf Vectorized](#TfidfVectorizer-Short-Emotion-Data)\n",
    "    \n",
    "3) **Long Emotion Data**\n",
    "- [Count Vectorized](#Count-Vectorized-Long-Emotion-Data)\n",
    "- [Tfidf Vectorized](#TfidfVectorizer-Long-Emotion-Data)\n",
    "    \n",
    "4) **Positive and Negative Sentences**\n",
    "- [Count Vectorized](#Count-Vectorized-Positive-and-Negative-Sentences)\n",
    "- [Tfidf Vectorized](#TfidfVectorizer-Positive-and-Negative-Sentences)\n",
    "    \n",
    "5) **Word Predictor**\n",
    "- [Model in of itself](#Word-Emotion-Data-Set)\n",
    "\n",
    "6) **Create Final Model**\n",
    "- [Final Model](#Final-Model)\n",
    "- [Pickle](#Saving-our-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've defined a lot of modelling functions in a separate .py file for cleanliness purposes, so we are going to import them here. That file also contains all the other needed imports so that will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Useful_Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all the necessary data first the training data\n",
    "Emotion_short = pd.read_csv('../data/Training_Data/2_Cleaned_Training_Data/Cleaned_Emotion_Analyzer.csv', index_col=0)\n",
    "Emotion_long = pd.read_csv('../data/Training_Data/2_Cleaned_Training_Data/Other_Cleaned_Emotion_Analyzer.csv', index_col=0)\n",
    "Pos_neg = pd.read_csv('../data/Training_Data/2_Cleaned_Training_Data/Cleaned_Pos_Neg_Sentences.csv', index_col=0)\n",
    "Word_Classifier = pd.read_csv('../data/Training_Data/1_Uncleaned_Training_Data/Andbrain_DataSet.csv', index_col=0)\n",
    "# Now the testing data\n",
    "Tester= pd.read_csv('../data/Testing_Data/4_Cleaned_Testing_Data/Final_Testing_Data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I'll do next might seem a little confusing but the purpose of it is to get my data to fit into the parameters of some of the later models. I'm going to change the value `0` into `-1` for the target column in each of the data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotion_short['Negativity'] = Emotion_short['Negativity'].apply(zero_to_neg_one)\n",
    "Emotion_long['Negativity'] = Emotion_long['Negativity'].apply(zero_to_neg_one)\n",
    "Pos_neg['Negativity'] = Pos_neg['Negativity'].apply(zero_to_neg_one)\n",
    "Tester['Irrational'] = Tester['Irrational'].apply(zero_to_neg_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotion_long.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pos_neg.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    259\n",
       "-1    223\n",
       "Name: Irrational, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tester.Irrational.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our baseline model equals 259/482 or 53.7%. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = Tester['Text']\n",
    "y_test = Tester['Irrational']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Emotion Data\n",
    "I called it \"short\" because in the original emotion listing there was only 6 emotions compared to the other emotion classifier with 12 emotions. Let's do some quick summary stats to get a feel for what will happen in modelling stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Negativity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  Negativity\n",
       "0      i just feel really helpless and heavy hearted           1\n",
       "1  ive enjoyed being able to slouch about relax a...           1\n",
       "2  i gave up my internship with the dmrg and am f...           1\n",
       "3                         i dont know i feel so lost           1\n",
       "4  i am a kindergarten teacher and i am thoroughl...           1"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emotion_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emotion_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    5451\n",
       "-1    4549\n",
       "Name: Negativity, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emotion_short.Negativity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, there's a decent amount of data here and a good amount of examples from both classes. So let's move on to modelling.\n",
    "The modelling process is largely an iterative experiment so it might be worthwhile to skip to the results. I repeated the labeling to help anyone who was looking through it keep track of where they are at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorized Short Emotion Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Emotion_short['Sentences']\n",
    "y_train = Emotion_short['Negativity']\n",
    "pipe_param =  { 'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "                'lr__C': [.005],\n",
    "                'lr__penalty': ['l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.663\n",
      "The accuracy score for your training data was: 0.7789\n",
      "The accuracy score for your testing data was: 0.533195020746888\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'lr__C': 0.005, 'lr__penalty': 'l2'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>14</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>16</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    14                   209\n",
       "Actual Irrational                  16                   243"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  {'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.90],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "              'nb__alpha': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for the grid search was: 0.9262\n",
      "The accuracy score for your training data was: 0.9976\n",
      "The accuracy score for your testing data was: 0.5311203319502075\n",
      "The best parameters were: {'cvec__max_df': 0.9, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'nb__alpha': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>54</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>57</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    54                   169\n",
       "Actual Irrational                  57                   202"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nae_vec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "                'rf__n_estimators': [50],\n",
    "                'rf__max_depth': [12, 13],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.5748\n",
      "The accuracy score for your training data was: 0.5834\n",
      "The accuracy score for your testing data was: 0.5373443983402489\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'rf__max_depth': 13, 'rf__n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                     0                   223\n",
       "Actual Irrational                   0                   259"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.90],\n",
    "                'cvec__ngram_range': [(1,3)],\n",
    "                'et__n_estimators': [50],\n",
    "                'et__max_depth': [12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.5621\n",
      "The accuracy score for your training data was: 0.5635\n",
      "The accuracy score for your testing data was: 0.5394190871369294\n",
      "The best parameters were: {'cvec__max_df': 0.9, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'et__max_depth': 12, 'et__n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                     1                   222\n",
       "Actual Irrational                   0                   259"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param = {  'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1,3)],\n",
    "                'ada__n_estimators': [100],\n",
    "             'ada__learning_rate': [.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.8287\n",
      "The accuracy score for your training data was: 0.8463\n",
      "The accuracy score for your testing data was: 0.5373443983402489\n",
      "The best parameters were: {'ada__learning_rate': 0.5, 'ada__n_estimators': 100, 'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>13</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>13</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    13                   210\n",
       "Actual Irrational                  13                   246"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer Short Emotion Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__min_df': [0],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'lr__C': [.005],\n",
    "                'lr__penalty': ['l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.5451\n",
      "The accuracy score for your training data was: 0.5451\n",
      "The accuracy score for your testing data was: 0.5373443983402489\n",
      "The best parameters were: {'lr__C': 0.005, 'lr__penalty': 'l2', 'tvec__max_df': 0.95, 'tvec__min_df': 0, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                     0                   223\n",
       "Actual Irrational                   0                   259"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  {'tvec__stop_words':['english'],\n",
    "                'tvec__min_df': [0],\n",
    "                'tvec__max_df': [.80],\n",
    "                'tvec__ngram_range': [(1, 3)],\n",
    "              'nb__alpha': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for the grid search was: 0.8809\n",
      "The accuracy score for your training data was: 0.9897\n",
      "The accuracy score for your testing data was: 0.5020746887966805\n",
      "The best parameters were: {'nb__alpha': 2, 'tvec__max_df': 0.8, 'tvec__min_df': 0, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>18</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>35</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    18                   205\n",
       "Actual Irrational                  35                   224"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nae_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__stop_words':['english'],\n",
    "                'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1, 3)],\n",
    "                'rf__n_estimators': [150, 200],\n",
    "                'rf__max_depth': [12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.5576\n",
      "The accuracy score for your training data was: 0.5567\n",
      "The accuracy score for your testing data was: 0.5352697095435685\n",
      "The best parameters were: {'rf__max_depth': 12, 'rf__n_estimators': 150, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                     0                   223\n",
       "Actual Irrational                   1                   258"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'et__n_estimators': [50],\n",
    "                'et__max_depth': [9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.5477\n",
      "The accuracy score for your training data was: 0.5459\n",
      "The accuracy score for your testing data was: 0.5373443983402489\n",
      "The best parameters were: {'et__max_depth': 9, 'et__n_estimators': 50, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                     0                   223\n",
       "Actual Irrational                   0                   259"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_tvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier Short Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param = {  'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.999, .95],\n",
    "                'tvec__ngram_range': [(3,4), (1,3)],\n",
    "                'ada__n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.8311\n",
      "The accuracy score for your training data was: 0.8497\n",
      "The accuracy score for your testing data was: 0.5311203319502075\n",
      "The best parameters were: {'ada__n_estimators': 100, 'tvec__max_df': 0.999, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>13</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>16</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    13                   210\n",
       "Actual Irrational                  16                   243"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_tvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorized Long Emotion Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Emotion_long['Sentences']\n",
    "y_train = Emotion_long['Negativity']\n",
    "pipe_param =  { 'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "                'lr__C': [.01],\n",
    "                'lr__penalty': ['l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6861857252494244\n",
      "The accuracy score for your training data was: 0.7246354566385265\n",
      "The accuracy score for your testing data was: 0.5\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'lr__C': 0.01, 'lr__penalty': 'l2'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>184</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>202</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   184                    39\n",
       "Actual Irrational                 202                    57"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  {'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.98],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "              'nb__alpha': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for the grid search was: 0.689357892044001\n",
      "The accuracy score for your training data was: 0.9554361729342543\n",
      "The accuracy score for your testing data was: 0.5954356846473029\n",
      "The best parameters were: {'cvec__max_df': 0.98, 'cvec__min_df': 0, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'nb__alpha': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>189</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>161</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   189                    34\n",
       "Actual Irrational                 161                    98"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nae_vec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier()\n",
    "pipe_param =  { 'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "                'rf__n_estimators': [100],\n",
    "                'rf__max_depth': [30],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6153747761575851\n",
      "The accuracy score for your training data was: 0.6155026861089793\n",
      "The accuracy score for your testing data was: 0.46473029045643155\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'rf__max_depth': 30, 'rf__n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   223                     0\n",
       "Actual Irrational                 258                     1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1,3)],\n",
    "                'et__n_estimators': [100, 50],\n",
    "                'et__max_depth': [9, 13]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6150166282936812\n",
      "The accuracy score for your training data was: 0.6150166282936812\n",
      "The accuracy score for your testing data was: 0.46265560165975106\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'et__max_depth': 9, 'et__n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   223                     0\n",
       "Actual Irrational                 259                     0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param = {  'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.999, .95],\n",
    "                'cvec__ngram_range': [(3,4), (1,3)],\n",
    "                'ada__n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.7028140189306729\n",
      "The accuracy score for your training data was: 0.7179073931951906\n",
      "The accuracy score for your testing data was: 0.5311203319502075\n",
      "The best parameters were: {'ada__n_estimators': 100, 'cvec__max_df': 0.999, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>177</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>180</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   177                    46\n",
       "Actual Irrational                 180                    79"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer Long Emotion Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'lr__C': [.01],\n",
    "                'lr__penalty': ['l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6150166282936812\n",
      "The accuracy score for your training data was: 0.6150166282936812\n",
      "The accuracy score for your testing data was: 0.46265560165975106\n",
      "The best parameters were: {'lr__C': 0.01, 'lr__penalty': 'l2', 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   223                     0\n",
       "Actual Irrational                 259                     0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  {'tvec__stop_words':['english'],\n",
    "                'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1, 3)],\n",
    "              'nb__alpha': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for the grid search was: 0.6504476848298798\n",
      "The accuracy score for your training data was: 0.7581478639038117\n",
      "The accuracy score for your testing data was: 0.5124481327800829\n",
      "The best parameters were: {'nb__alpha': 2, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>217</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>229</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   217                     6\n",
       "Actual Irrational                 229                    30"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nae_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__stop_words':['english'],\n",
    "                'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1, 3)],\n",
    "                'rf__n_estimators': [150, 200],\n",
    "                'rf__max_depth': [12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6150166282936812\n",
      "The accuracy score for your training data was: 0.6150166282936812\n",
      "The accuracy score for your testing data was: 0.46265560165975106\n",
      "The best parameters were: {'rf__max_depth': 12, 'rf__n_estimators': 150, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   223                     0\n",
       "Actual Irrational                 259                     0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'et__n_estimators': [100],\n",
    "                'et__max_depth': [9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6150166282936812\n",
      "The accuracy score for your training data was: 0.6150166282936812\n",
      "The accuracy score for your testing data was: 0.46265560165975106\n",
      "The best parameters were: {'et__max_depth': 9, 'et__n_estimators': 100, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   223                     0\n",
       "Actual Irrational                 259                     0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_tvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier Long Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param = {  'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'ada__n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6989511383985674\n",
      "The accuracy score for your training data was: 0.7177539012535176\n",
      "The accuracy score for your testing data was: 0.5311203319502075\n",
      "The best parameters were: {'ada__n_estimators': 100, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>178</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>181</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   178                    45\n",
       "Actual Irrational                 181                    78"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_tvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorized Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Pos_neg['Sentences']\n",
    "y_train = Pos_neg['Negativity']\n",
    "pipe_param =  { 'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.9],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "                'lr__C': [.005],\n",
    "                'lr__penalty': ['l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6800967225435415\n",
      "The accuracy score for your training data was: 0.7632585040682286\n",
      "The accuracy score for your testing data was: 0.5062240663900415\n",
      "The best parameters were: {'cvec__max_df': 0.9, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'lr__C': 0.005, 'lr__penalty': 'l2'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>79</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>94</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    79                   144\n",
       "Actual Irrational                  94                   165"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  {'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "              'nb__alpha': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for the grid search was: 0.7232951017874064\n",
      "The accuracy score for your training data was: 0.9783027807731268\n",
      "The accuracy score for your testing data was: 0.5912863070539419\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'nb__alpha': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>95</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>69</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    95                   128\n",
       "Actual Irrational                  69                   190"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nae_vec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "                'rf__n_estimators': [50],\n",
    "                'rf__max_depth': [8, 12],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6173577753814985\n",
      "The accuracy score for your training data was: 0.6701303793745711\n",
      "The accuracy score for your testing data was: 0.5124481327800829\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'cvec__stop_words': 'english', 'rf__max_depth': 12, 'rf__n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>139</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>151</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   139                    84\n",
       "Actual Irrational                 151                   108"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1,3)],\n",
    "                'et__n_estimators': [50],\n",
    "                'et__max_depth': [9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.5926543149364442\n",
      "The accuracy score for your training data was: 0.6280756788550143\n",
      "The accuracy score for your testing data was: 0.4896265560165975\n",
      "The best parameters were: {'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3), 'et__max_depth': 9, 'et__n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>185</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>208</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   185                    38\n",
       "Actual Irrational                 208                    51"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param = {  'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1,3)],\n",
    "                'ada__n_estimators': [50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6029800999901971\n",
      "The accuracy score for your training data was: 0.6147436525830801\n",
      "The accuracy score for your testing data was: 0.5\n",
      "The best parameters were: {'ada__n_estimators': 50, 'cvec__max_df': 0.95, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>174</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>192</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   174                    49\n",
       "Actual Irrational                 192                    67"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_cvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'lr__C': [.005],\n",
    "                'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6681371107407771\n",
      "The accuracy score for your training data was: 0.724798222396497\n",
      "The accuracy score for your testing data was: 0.5726141078838174\n",
      "The best parameters were: {'lr__C': 0.005, 'lr__penalty': 'l2', 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>85</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>68</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    85                   138\n",
       "Actual Irrational                  68                   191"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  {'tvec__stop_words':['english'],\n",
    "                'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "              'nb__alpha': [2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for the grid search was: 0.7248308989314773\n",
      "The accuracy score for your training data was: 0.9742835669705584\n",
      "The accuracy score for your testing data was: 0.5933609958506224\n",
      "The best parameters were: {'nb__alpha': 2, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>96</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>69</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                    96                   127\n",
       "Actual Irrational                  69                   190"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nae_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__stop_words':['english'],\n",
    "                'tvec__min_df': [0],\n",
    "                'tvec__max_df': [.999],\n",
    "                'tvec__ngram_range': [(1, 3)],\n",
    "                'rf__n_estimators': [150, 200],\n",
    "                'rf__max_depth': [9, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6578766787569846\n",
      "The accuracy score for your training data was: 0.7307126752279188\n",
      "The accuracy score for your testing data was: 0.5394190871369294\n",
      "The best parameters were: {'rf__max_depth': 9, 'rf__n_estimators': 200, 'tvec__max_df': 0.999, 'tvec__min_df': 0, 'tvec__ngram_range': (1, 3), 'tvec__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>138</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>137</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   138                    85\n",
       "Actual Irrational                 137                   122"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for_tfidf(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param =  { 'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'et__n_estimators': [50],\n",
    "                'et__max_depth': [9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.5808254092736006\n",
      "The accuracy score for your training data was: 0.6025226285004738\n",
      "The accuracy score for your testing data was: 0.45850622406639\n",
      "The best parameters were: {'et__max_depth': 9, 'et__n_estimators': 50, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>175</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>213</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   175                    48\n",
       "Actual Irrational                 213                    46"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_tree_tvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier Positive and Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param = {  'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "                'ada__n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.6296768290690455\n",
      "The accuracy score for your training data was: 0.6530732281148907\n",
      "The accuracy score for your testing data was: 0.508298755186722\n",
      "The best parameters were: {'ada__n_estimators': 100, 'tvec__max_df': 0.95, 'tvec__min_df': 1, 'tvec__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>142</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>156</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   142                    81\n",
       "Actual Irrational                 156                   103"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_tvec(pipe_param, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Emotion Data Set\n",
    "\n",
    "This Data set is based in giving words a certain weight based on how likely they would occur in a sentence that has certain  emotions. I'm going to search through each sentence in the testing data set for these words, add up their values, and determine whether the sentence has a negative emotion or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disgust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>happy</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.047832</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.015944</td>\n",
       "      <td>0.040179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.137363</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.002659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>academy</th>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accept</th>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.048872</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>0.024812</td>\n",
       "      <td>0.038346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           disgust  surprise   neutral     anger       sad     happy      fear\n",
       "word                                                                          \n",
       "ability   0.004464  0.047832  0.000638  0.023597  0.013393  0.015944  0.040179\n",
       "able      0.000017  0.000182  0.000409  0.000176  0.000219  0.000244  0.000186\n",
       "abuse     0.000532  0.000177  0.000177  0.137363  0.001241  0.001595  0.002659\n",
       "academy   0.007143  0.021429  0.007143  0.007143  0.007143  0.092857  0.035714\n",
       "accept    0.008271  0.006767  0.000752  0.048872  0.018797  0.024812  0.038346"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Classifier.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next line is a model in of itself. It can be used on any word based data to help determine whether it's overall positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_class_model(df, df_sentences, word_df_name):\n",
    "    pos_emo_list = [] # positive emotion list, I'm going to put the non-negative weights in here\n",
    "    neg_emo_list = [] # negative emotion list, I'm going to put the negative weights in here\n",
    "    temp_df = df.copy()\n",
    "    # function to determine weight per sentence/row.\n",
    "    def find_weights(sentence): \n",
    "        pos_emo = 0\n",
    "        neg_emo = 0\n",
    "        for word in sentence.split():\n",
    "            if (word + \" \") in word_df_name.index: # there was a trailing white space for the words in the index\n",
    "                neg_emo += word_df_name.loc[(word + ' ')]['disgust'] # Grab the weight\n",
    "                neg_emo += word_df_name.loc[(word + ' ')]['anger']\n",
    "                neg_emo += word_df_name.loc[(word + ' ')]['sad']\n",
    "                neg_emo += word_df_name.loc[(word + ' ')]['fear']\n",
    "                pos_emo += word_df_name.loc[(word + ' ')]['happy']\n",
    "                pos_emo += word_df_name.loc[(word + ' ')]['surprise']\n",
    "                pos_emo += word_df_name.loc[(word + ' ')]['neutral']\n",
    "        pos_emo_list.append(pos_emo)\n",
    "        neg_emo_list.append(neg_emo)\n",
    "    temp_df[df_sentences].apply(find_weights) # applying the function should create two lists the same length as our data\n",
    "    # Incorporate lists into dataframe\n",
    "    temp_df['Positive_Word_Weight'] = pos_emo_list\n",
    "    temp_df['Negative_Word_Weight'] = neg_emo_list\n",
    "    # Compare the columns return 1s for Negative, -1s for Positive\n",
    "    Final_Predictions = np.where(temp_df['Positive_Word_Weight'] < temp_df['Negative_Word_Weight'], 1, -1) \n",
    "    # return final prediction        \n",
    "    return Final_Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_column = word_class_model(Tester, 'Text', Word_Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester['Word Predictions'] = final_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Irrational</th>\n",
       "      <th>Word Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh of course</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lately i ve been having these attack that are ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well it becomes a total preoccupation i can t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patrick that s my husband he wa late he lost h...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well somehow i finally got myself together and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Irrational  \\\n",
       "0                                       oh of course          -1   \n",
       "1  lately i ve been having these attack that are ...          -1   \n",
       "2  well it becomes a total preoccupation i can t ...           1   \n",
       "3  patrick that s my husband he wa late he lost h...           1   \n",
       "4  well somehow i finally got myself together and...           1   \n",
       "\n",
       "   Word Predictions  \n",
       "0                -1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that it works\n",
    "Tester.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for your testing data was: 0.43568464730290457\n"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy score for your testing data was: {accuracy_score(final_column, y_test)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>115</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>164</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   115                   108\n",
       "Actual Irrational                 164                    95"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, final_column),\n",
    "                                         index=['Actual Rational', 'Actual Irrational'],\n",
    "                                         columns=['Predicted Rational', 'Predicted Irrational'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow pretty bad model. I'm going to need the misclassification rate for the final model later so i'll put that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_miscl = 1 - (accuracy_score(final_column, y_test))\n",
    "word_weights = (1/2)*np.log((1-word_miscl)/word_miscl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our final model we're going to combine the best model from each data set and based on how accurate they were, determine a final prediction. It's interesting to note that Naive Bayes was best model in general. The best Data Set was the long Emotion dataset with the positive and negative sentences coming in a close second. I'm going to create weights for each model's predictions and that will help reduce the value of the worse models' predictions.<br>\n",
    "<br>\n",
    "Final_Predictions = $\\text{sign}(\\sum(\\hat{y_1}w_1 + \\hat{y_2}w_2....))$ <br>\n",
    "                    $w_t = \\frac{1}{2}log(\\frac{1 - \\epsilon_t}{\\epsilon_t})$ <br>\n",
    "                    $\\epsilon_t = $ Misclassification Rate\n",
    "                    \n",
    "<br>\n",
    "First I'm going to put together the final models from each data set which I chose based on their ability to compliment each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Short Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Emotion_short['Sentences']\n",
    "y_train = Emotion_short['Negativity']\n",
    "pipe = Pipeline([('cvec', CountVectorizer(stop_words = 'english')),\n",
    "                 ('ada', AdaBoostClassifier(random_state=42))])\n",
    "pipe_param = {  'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.95],\n",
    "                'cvec__ngram_range': [(1,3)],\n",
    "                'ada__n_estimators': [100],\n",
    "             'ada__learning_rate': [.5]}\n",
    "emot_short_gs = GridSearchCV(pipe, param_grid=pipe_param, cv=5)\n",
    "emot_short_gs.fit(X_train, y_train)\n",
    "# For our final predictions\n",
    "emot_short_preds = emot_short_gs.predict(X_test)\n",
    "# Get misclassification rate\n",
    "emot_short_miscl = 1 - (accuracy_score(emot_short_preds, y_test))\n",
    "# Get the appropriate weights\n",
    "emot_short_weight = (1/2)*np.log((1-emot_short_miscl)/emot_short_miscl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Long Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Emotion_long['Sentences']\n",
    "y_train = Emotion_long['Negativity']\n",
    "pipe = Pipeline([('cvec', CountVectorizer()),\n",
    "                 ('nb', MultinomialNB())])\n",
    "pipe_param =  {'cvec__stop_words':['english'],\n",
    "                'cvec__min_df': [1],\n",
    "                'cvec__max_df': [.98],\n",
    "                'cvec__ngram_range': [(1, 3)],\n",
    "              'nb__alpha': [2]}\n",
    "emot_long_gs = GridSearchCV(pipe, param_grid=pipe_param, cv=5)\n",
    "emot_long_gs.fit(X_train, y_train)\n",
    "# For our final predictions\n",
    "emot_long_preds = emot_long_gs.predict(X_test)\n",
    "# Get misclassification rate\n",
    "emot_long_miscl = 1 - (accuracy_score(emot_long_preds, y_test))\n",
    "# Get the appropriate weights\n",
    "emot_long_weight = (1/2)*np.log((1-emot_long_miscl)/emot_long_miscl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive and Negative Sentences Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Pos_neg['Sentences']\n",
    "y_train = Pos_neg['Negativity']\n",
    "pipe = Pipeline([('tvec', TfidfVectorizer()),\n",
    "                 ('nb', MultinomialNB())])\n",
    "pipe_param =  {'tvec__stop_words':['english'],\n",
    "                'tvec__min_df': [1],\n",
    "                'tvec__max_df': [.95],\n",
    "                'tvec__ngram_range': [(1,3)],\n",
    "              'nb__alpha': [2]}\n",
    "pos_neg_gs = GridSearchCV(pipe, param_grid=pipe_param, cv=5)\n",
    "pos_neg_gs.fit(X_train, y_train)\n",
    "# For our final predictions\n",
    "pos_neg_preds = pos_neg_gs.predict(X_test)\n",
    "# Get misclassification rate\n",
    "pos_neg_miscl = 1 - (accuracy_score(pos_neg_preds, y_test))\n",
    "# Get the appropriate weights\n",
    "pos_neg_weight = (1/2)*np.log((1-pos_neg_miscl)/pos_neg_miscl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester['Emotion_Long_Preds'] = emot_long_preds\n",
    "Tester['Pos_Neg_Preds'] = pos_neg_preds\n",
    "Tester['Emotion_Short_Preds'] = emot_short_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've already put together the final model for the word classifier so we'll implement the equation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    " Tester['Final Prediction'] = ((Tester['Emotion_Long_Preds']*emot_long_weight)+ \n",
    "                                (Tester['Pos_Neg_Preds']*pos_neg_weight) + \n",
    "                                (Tester['Emotion_Short_Preds']*emot_short_weight) +\n",
    "                              (Tester['Word Predictions']*word_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create final predictions based off weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust(value):\n",
    "    if value > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get final test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6327800829875518\n"
     ]
    }
   ],
   "source": [
    "Tester['Final Prediction'] = Tester['Final Prediction'].apply(adjust)\n",
    "final_preds = list(Tester['Final Prediction'])\n",
    "print(accuracy_score(final_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Rational</th>\n",
       "      <th>Predicted Irrational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Rational</th>\n",
       "      <td>146</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Irrational</th>\n",
       "      <td>100</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Rational  Predicted Irrational\n",
       "Actual Rational                   146                    77\n",
       "Actual Irrational                 100                   159"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, final_preds),\n",
    "                                         index=['Actual Rational', 'Actual Irrational'],\n",
    "                                         columns=['Predicted Rational', 'Predicted Irrational'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create a final function that allows easy use of the combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of model variables.\n",
    "final_model_list = [emot_long_gs, pos_neg_gs, emot_short_gs]\n",
    "# list of weights for each model\n",
    "final_weights_list =[emot_long_weight, pos_neg_weight,emot_short_weight, word_weights] \n",
    "# final model function\n",
    "def combined_model_predictor(df_to_predict, feature, word_df_name, final_model_list, weight_list):\n",
    "        # Inculcates word class function to predict\n",
    "        def word_class_model(df, df_sentences, word_df_name):\n",
    "            pos_emo_list = [] # positive emotion list, I'm going to put the non-negative weights in here\n",
    "            neg_emo_list = [] # negative emotion list, I'm going to put the negative weights in here\n",
    "            temp_df = df.copy()\n",
    "            \n",
    "            # function to determine weight per sentence/row.\n",
    "            def find_weights(sentence): \n",
    "                pos_emo = 0\n",
    "                neg_emo = 0\n",
    "                for word in sentence.split():\n",
    "                    if (word + \" \") in word_df_name.index: # there was a trailing white space for the words in the index\n",
    "                        neg_emo += word_df_name.loc[(word + ' ')]['disgust'] # Grab the weight\n",
    "                        neg_emo += word_df_name.loc[(word + ' ')]['anger']\n",
    "                        neg_emo += word_df_name.loc[(word + ' ')]['sad']\n",
    "                        neg_emo += word_df_name.loc[(word + ' ')]['fear']\n",
    "                        pos_emo += word_df_name.loc[(word + ' ')]['happy']\n",
    "                        pos_emo += word_df_name.loc[(word + ' ')]['surprise']\n",
    "                        pos_emo += word_df_name.loc[(word + ' ')]['neutral']\n",
    "                pos_emo_list.append(pos_emo)\n",
    "                neg_emo_list.append(neg_emo)\n",
    "                \n",
    "            temp_df[df_sentences].apply(find_weights) # applying the function should create two lists the same length as our data\n",
    "            # Incorporate lists into dataframe\n",
    "            temp_df['Positive_Word_Weight'] = pos_emo_list\n",
    "            temp_df['Negative_Word_Weight'] = neg_emo_list\n",
    "            # Compare the columns return 1s for Negative, -1s for Positive\n",
    "            Final_Predictions = np.where(temp_df['Positive_Word_Weight'] < temp_df['Negative_Word_Weight'], 1, -1)    \n",
    "            return Final_Predictions\n",
    "        predictions = []\n",
    "        for model in final_model_list:\n",
    "            predictions.append(model.predict(df_to_predict[feature]))\n",
    "        word_model = word_class_model(df_to_predict, feature, word_df_name) \n",
    "        predictions.append(word_model)\n",
    "        predicted_weights = ((np.array(predictions[0])*weight_list[0])+\n",
    "                                (np.array(predictions[1])*weight_list[1]) +\n",
    "                                (np.array(predictions[2])*weight_list[2]) +\n",
    "                              (np.array(predictions[3])*weight_list[3]))        \n",
    "        final_predictions = []\n",
    "        for pred in predicted_weights:\n",
    "                if pred > 0:\n",
    "                    final_predictions.append(1)\n",
    "                else:\n",
    "                    final_predictions.append(-1)\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482\n"
     ]
    }
   ],
   "source": [
    "# Test to confirm that it worked\n",
    "final_prediction_list = combined_model_predictor(Tester, 'Text', Word_Classifier, final_model_list)\n",
    "print(len(final_prediction_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Save the first three models using pickle. <br>\n",
    "2) Save the word based model and the final model that combines everything together into their own .py file. For this I will simply copy and paste it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_list = [emot_long_gs, pos_neg_gs, emot_short_gs]\n",
    "final_weights_list =[emot_long_weight, pos_neg_weight,emot_short_weight, word_weights] \n",
    "final_model_dictionary ={'Weights': final_weights_list, 'Models': final_model_list}\n",
    "outfile = open('../Final_Models/Three_Models','w+b')\n",
    "pickle.dump(final_model_dictionary, outfile)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
